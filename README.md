# image-caption-generator

Image Captioning Model based on OpenAI's CLIP and GPT-2. The Model uses a Mapping module to "translate" CLIP embeddings ​​to GPT-2. The model is trained on the Flickr30k dataset, downloaded from Kaggle

Link for video: https://drive.google.com/drive/folders/1fWKJXY0yWo4WJAtK1cO4RCETxxPZ0bgj?usp=share_link

Sample output:

![image](https://github.com/sacchinbhg/image-caption-generator/assets/61612220/281f0b72-feda-4649-b6fe-1d83422e0fd5)
