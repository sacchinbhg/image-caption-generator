# image-caption-generator

Image Captioning Model based on OpenAI's CLIP and GPT-2. The Model uses a Mapping module to "translate" CLIP embeddings ​​to GPT-2. The model is trained on the Flickr30k dataset, downloaded from Kaggle

Link for video: https://drive.google.com/drive/folders/1fWKJXY0yWo4WJAtK1cO4RCETxxPZ0bgj?usp=share_link

Sample output:

![Screenshot from 2023-07-04 12-41-34](https://github.com/sacchinbhg/image-caption-generator/assets/61612220/ee5ca2f4-86d7-4c90-b57c-bcafd2edad0f)
